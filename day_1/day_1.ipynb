{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fc4aae6-cbb0-4af1-91a2-f28c1f71e7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([42,  0,  0,  ...,  0,  0,  0], dtype=torch.uint8)\n",
      "tensor([84,  0,  0,  ...,  0,  0,  0], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "#-----------------pytorch中的主要函数------------------\n",
    "#抽样函数\n",
    "import torch\n",
    "torch.seed()#生成一个64位随机数\n",
    "torch.manual_seed(42)#设置生成随机数的种子并返回一个torch.generator对象\n",
    "torch.initial_seed()#返回生成随机数的原始种子值\n",
    "torch.get_rng_state()#生成一个随机生成器状态\n",
    "rng_state1 = torch.get_rng_state()\n",
    "print(rng_state1)\n",
    "torch.set_rng_state(rng_state1*2)#设定随机生成器的状态\n",
    "rng_state2 = torch.get_rng_state()\n",
    "print(rng_state2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecdf1a79-d6fa-402c-8b59-da2c615eb4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\.conda\\envs\\dlr\\lib\\site-packages (4.67.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\.conda\\envs\\dlr\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e360f3b-2eef-4200-a3fd-f69176ea6152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一次反向传播后:\n",
      "x.grad: tensor([36.])\n",
      "y.grad: tensor([24.])\n",
      "\n",
      "第二次反向传播后:\n",
      "x.grad: tensor([36.])\n",
      "y.grad: tensor([24.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建需要梯度的叶子节点\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = torch.tensor([3.0], requires_grad=True)\n",
    "\n",
    "# 前向计算\n",
    "z = x * y\n",
    "loss = z ** 2\n",
    "\n",
    "# 方法1：使用 loss.backward(retain_graph=True)\n",
    "loss.backward(retain_graph=True)  # 保留计算图\n",
    "print(f\"第一次反向传播后:\")\n",
    "print(f\"x.grad: {x.grad}\")  # 36\n",
    "print(f\"y.grad: {y.grad}\")  # 24\n",
    "\n",
    "# 手动清零梯度（注意：只是清零梯度值，计算图还在）\n",
    "x.grad = None\n",
    "y.grad = None\n",
    "\n",
    "# 方法2：再次反向传播（现在可以了）\n",
    "torch.autograd.backward(loss)\n",
    "print(f\"\\n第二次反向传播后:\")\n",
    "print(f\"x.grad: {x.grad}\")  # 再次计算得到 36\n",
    "print(f\"y.grad: {y.grad}\")  # 再次计算得到 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43b440b5-5ed4-48a7-a993-99f2545bdccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([6.], grad_fn=<MulBackward0>),)\n",
      "(tensor([2.]),)\n"
     ]
    }
   ],
   "source": [
    "#torch.autograd.grad()\n",
    "import torch\n",
    "x = torch.tensor([3.],requires_grad = True)\n",
    "y = torch.pow(x,2)\n",
    "grad1 = torch.autograd.grad(y,x,create_graph = True)\n",
    "print(grad1)\n",
    "grad2 = torch.autograd.grad(grad1[0],x)\n",
    "print(grad2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fa6fa52-20ac-4e73-b399-ac2a2fbe9ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24.)\n"
     ]
    }
   ],
   "source": [
    "#---------------pytorch统计函数-----------------\n",
    "import torch\n",
    "a = torch.tensor([1.0,2.0,3.0,4.0])\n",
    "print(torch.prod(a))#乘积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72e984f9-e6f1-4e0b-894a-c25676bd7565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0041, 0.6808],\n",
      "        [0.0089, 0.4917]])\n",
      "tensor(1.1856) tensor(1.1856) tensor([[0.6850],\n",
      "        [0.5006]]) tensor([[0.0131, 1.1725]])\n"
     ]
    }
   ],
   "source": [
    "#求和\n",
    "import torch\n",
    "a = torch.rand(2,2)#随机生成一个2*2矩阵\n",
    "print(a)\n",
    "a1 = torch.sum(a)\n",
    "a2 = torch.sum(a,dim = (0,1))#dim等于0队列求和 等于1对行求和\n",
    "a3 = torch.sum(a,dim = 1,keepdim = True)#keepdim保留结果的维度\n",
    "a4 = torch.sum(a,dim = 0,keepdim = True)\n",
    "print(a1,a2,a3,a4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "130b5c35-408e-437b-8910-8ff354123b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8352, 0.1854],\n",
      "        [0.6379, 0.6145]])\n",
      "tensor(0.5683)\n",
      "tensor([[0.5103],\n",
      "        [0.6262]])\n",
      "tensor([[0.7366, 0.4000]])\n",
      "tensor(0.5683)\n"
     ]
    }
   ],
   "source": [
    "#平均值\n",
    "a = torch.rand(2,2)\n",
    "a1 = torch.mean(a)\n",
    "a2 = torch.mean(a,dim = 1,keepdim = True)\n",
    "a3 = torch.mean(a,dim = 0,keepdim = True)\n",
    "a4 = torch.mean(a,dim = (0,1))\n",
    "print(a)\n",
    "print(a1)\n",
    "print(a2)\n",
    "print(a3)\n",
    "print(a4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a32fcbda-214e-45fb-b58d-3218fb9f7c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1453, 0.7352],\n",
      "        [0.1456, 0.0760]])\n",
      "tensor(0.7352)\n",
      "torch.return_types.max(\n",
      "values=tensor([[0.7352],\n",
      "        [0.1456]]),\n",
      "indices=tensor([[1],\n",
      "        [0]]))\n",
      "torch.return_types.max(\n",
      "values=tensor([[0.1456, 0.7352]]),\n",
      "indices=tensor([[1, 0]]))\n"
     ]
    }
   ],
   "source": [
    "#最大值\n",
    "a = torch.rand(2,2)\n",
    "a1 = torch.max(a)\n",
    "a2 = torch.max(a,dim = 1,keepdim = True)\n",
    "a3 = torch.max(a,dim = 0,keepdim = True)\n",
    "print(a)\n",
    "print(a1)\n",
    "print(a2)\n",
    "print(a3)\n",
    "#最小值同理 用torch.min函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "576ed958-b510-4491-ac5c-d3f79a6a01f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3048, 0.7487, 0.0872],\n",
      "        [0.9910, 0.3536, 0.8608],\n",
      "        [0.8386, 0.0283, 0.6782]])\n",
      "tensor(0.6782)\n",
      "torch.return_types.median(\n",
      "values=tensor([[0.3048],\n",
      "        [0.8608],\n",
      "        [0.6782]]),\n",
      "indices=tensor([[0],\n",
      "        [2],\n",
      "        [2]]))\n",
      "torch.return_types.median(\n",
      "values=tensor([[0.8386, 0.3536, 0.6782]]),\n",
      "indices=tensor([[2, 1, 2]]))\n"
     ]
    }
   ],
   "source": [
    "#中位数\n",
    "a = torch.rand(3,3)\n",
    "a1 = torch.median(a)\n",
    "a2 = torch.median(a,dim = 1,keepdim = True)\n",
    "a3 = torch.median(a,dim = 0,keepdim = True)\n",
    "print(a)\n",
    "print(a1)\n",
    "print(a2)\n",
    "print(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "027d35c9-14d9-4ca6-bf24-7817e4a9c828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1250, 0.5869, 0.5045, 0.8987, 0.8551, 0.3928, 0.9676, 0.6524, 0.1898,\n",
      "         0.9893],\n",
      "        [0.0295, 0.4268, 0.0102, 0.1591, 0.5835, 0.6335, 0.5721, 0.3427, 0.2330,\n",
      "         0.4617],\n",
      "        [0.8992, 0.7195, 0.1406, 0.8332, 0.4989, 0.6686, 0.1325, 0.9412, 0.4899,\n",
      "         0.8239],\n",
      "        [0.7685, 0.0921, 0.3204, 0.9481, 0.4835, 0.1664, 0.1954, 0.4896, 0.8400,\n",
      "         0.1820],\n",
      "        [0.6034, 0.8791, 0.3861, 0.7537, 0.5626, 0.7481, 0.4266, 0.0125, 0.6743,\n",
      "         0.6083],\n",
      "        [0.9078, 0.0796, 0.0481, 0.6453, 0.1891, 0.7718, 0.8126, 0.5951, 0.8554,\n",
      "         0.3873],\n",
      "        [0.5473, 0.6716, 0.9901, 0.3919, 0.4433, 0.0503, 0.0464, 0.9867, 0.0226,\n",
      "         0.0099],\n",
      "        [0.7377, 0.8883, 0.5586, 0.1437, 0.8726, 0.2016, 0.0847, 0.7568, 0.6720,\n",
      "         0.1259],\n",
      "        [0.0960, 0.2300, 0.9126, 0.0803, 0.4656, 0.7938, 0.1763, 0.6281, 0.8881,\n",
      "         0.7868],\n",
      "        [0.9870, 0.0558, 0.2993, 0.7850, 0.5864, 0.0010, 0.1038, 0.3170, 0.6433,\n",
      "         0.2316]])\n",
      "torch.return_types.mode(\n",
      "values=tensor([0.1250, 0.0102, 0.1325, 0.0921, 0.0125, 0.0481, 0.0099, 0.0847, 0.0803,\n",
      "        0.0010]),\n",
      "indices=tensor([0, 2, 6, 1, 7, 2, 9, 6, 3, 5]))\n",
      "torch.return_types.mode(\n",
      "values=tensor([[0.1250],\n",
      "        [0.0102],\n",
      "        [0.1325],\n",
      "        [0.0921],\n",
      "        [0.0125],\n",
      "        [0.0481],\n",
      "        [0.0099],\n",
      "        [0.0847],\n",
      "        [0.0803],\n",
      "        [0.0010]]),\n",
      "indices=tensor([[0],\n",
      "        [2],\n",
      "        [6],\n",
      "        [1],\n",
      "        [7],\n",
      "        [2],\n",
      "        [9],\n",
      "        [6],\n",
      "        [3],\n",
      "        [5]]))\n",
      "torch.return_types.mode(\n",
      "values=tensor([[0.0295, 0.0558, 0.0102, 0.0803, 0.1891, 0.0010, 0.0464, 0.0125, 0.0226,\n",
      "         0.0099]]),\n",
      "indices=tensor([[1, 9, 1, 8, 5, 9, 6, 4, 6, 6]]))\n"
     ]
    }
   ],
   "source": [
    "#众数\n",
    "a = torch.rand(10,10)\n",
    "a1 = torch.mode(a)\n",
    "a2 = torch.mode(a,dim = 1,keepdim = True)\n",
    "a3 = torch.mode(a,dim = 0,keepdim = True)\n",
    "print(a)\n",
    "print(a1)\n",
    "print(a2)\n",
    "print(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80c84534-3a9c-45d7-a2d6-9260ff9479df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9867, 0.7957, 0.8740],\n",
      "        [0.0795, 0.4092, 0.7500],\n",
      "        [0.6472, 0.1135, 0.4446]])\n",
      "tensor(0.1057)\n",
      "tensor(0.3252)\n",
      "tensor([[0.0092],\n",
      "        [0.1124],\n",
      "        [0.0726]])\n",
      "tensor([[0.2101, 0.1170, 0.0488]])\n"
     ]
    }
   ],
   "source": [
    "#方差\n",
    "a = torch.rand(3,3)\n",
    "a1 = torch.var(a)\n",
    "a4 = torch.std(a)#标准差\n",
    "a2 = torch.var(a,dim = 1,keepdim = True)\n",
    "a3 = torch.var(a,dim = 0,keepdim = True)\n",
    "print(a)\n",
    "print(a1)\n",
    "print(a4)\n",
    "print(a2)\n",
    "print(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "934eac90-16d8-42ec-a2e9-565393030a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4996, 0.8052, 0.0389, 0.8163],\n",
      "        [0.7147, 0.0010, 0.9159, 0.0974],\n",
      "        [0.6824, 0.8870, 0.5038, 0.5798]])\n",
      "tensor([[0.0922, 0.7313, 0.7137, 0.2561]])\n",
      "tensor([[0.5917, 1.5365, 0.7526, 1.0724],\n",
      "        [0.8068, 0.7322, 1.6296, 0.3535],\n",
      "        [0.7746, 1.6183, 1.2176, 0.8359]])\n",
      "tensor([[0.5917, 1.5365, 0.7526, 1.0724],\n",
      "        [0.8068, 0.7322, 1.6296, 0.3535],\n",
      "        [0.7746, 1.6183, 1.2176, 0.8359]])\n",
      "tensor([[0.5917, 1.5365, 0.7526, 1.0724],\n",
      "        [0.8068, 0.7322, 1.6296, 0.3535],\n",
      "        [0.7746, 1.6183, 1.2176, 0.8359]])\n",
      "tensor([[ 0.4074,  0.0739, -0.6749,  0.5602],\n",
      "        [ 0.6225, -0.7303,  0.2022, -0.1587],\n",
      "        [ 0.5903,  0.1558, -0.2099,  0.3237]])\n",
      "tensor([[ 0.4074,  0.0739, -0.6749,  0.5602],\n",
      "        [ 0.6225, -0.7303,  0.2022, -0.1587],\n",
      "        [ 0.5903,  0.1558, -0.2099,  0.3237]])\n",
      "tensor([[ 0.4074,  0.0739, -0.6749,  0.5602],\n",
      "        [ 0.6225, -0.7303,  0.2022, -0.1587],\n",
      "        [ 0.5903,  0.1558, -0.2099,  0.3237]])\n",
      "tensor([[0.0460, 0.5888, 0.0277, 0.2090],\n",
      "        [0.0659, 0.0007, 0.6537, 0.0249],\n",
      "        [0.0629, 0.6487, 0.3596, 0.1485]])\n",
      "tensor([[0.0460, 0.5888, 0.0277, 0.2090],\n",
      "        [0.0659, 0.0007, 0.6537, 0.0249],\n",
      "        [0.0629, 0.6487, 0.3596, 0.1485]])\n",
      "tensor([[0.0460, 0.5888, 0.0277, 0.2090],\n",
      "        [0.0659, 0.0007, 0.6537, 0.0249],\n",
      "        [0.0629, 0.6487, 0.3596, 0.1485]])\n",
      "tensor([[5.4206e+00, 1.1011e+00, 5.4443e-02, 3.1876e+00],\n",
      "        [7.7548e+00, 1.3052e-03, 1.2832e+00, 3.8032e-01],\n",
      "        [7.4049e+00, 1.2130e+00, 7.0594e-01, 2.2641e+00]])\n",
      "tensor([[5.4206e+00, 1.1011e+00, 5.4443e-02, 3.1876e+00],\n",
      "        [7.7548e+00, 1.3052e-03, 1.2832e+00, 3.8032e-01],\n",
      "        [7.4049e+00, 1.2130e+00, 7.0594e-01, 2.2641e+00]])\n",
      "tensor([[5.4206e+00, 1.1011e+00, 5.4443e-02, 3.1876e+00],\n",
      "        [7.7548e+00, 1.3052e-03, 1.2832e+00, 3.8032e-01],\n",
      "        [7.4049e+00, 1.2130e+00, 7.0594e-01, 2.2641e+00]])\n"
     ]
    }
   ],
   "source": [
    "#------------------矩阵运算-----------------------\n",
    "import torch\n",
    "a = torch.rand(3,4)\n",
    "b = torch.rand(1,4)\n",
    "print(a)\n",
    "print(b)\n",
    "#四则运算\n",
    "print(a+b)\n",
    "print(torch.add(a,b))#torch.add加法函数\n",
    "print(b.add(a))\n",
    "#---------------------------------------\n",
    "print(a-b)\n",
    "print(torch.sub(a,b))#减法\n",
    "print(a.sub(b))\n",
    "#---------------------------------------\n",
    "print(a*b)\n",
    "print(torch.mul(a,b))#乘法\n",
    "print(a.mul(b))\n",
    "#---------------------------------------\n",
    "print(a/b)\n",
    "print(torch.div(a,b))#除法\n",
    "print(a.div(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79b9ec77-dbc8-44a5-a783-3034f21647d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9309, 0.3685, 0.4900, 0.7922],\n",
      "        [0.6131, 0.5386, 0.9820, 0.3026],\n",
      "        [0.9763, 0.6562, 0.5117, 0.8219],\n",
      "        [0.5077, 0.6758, 0.8220, 0.8233]])\n",
      "tensor([[1.0742, 2.7136, 2.0409, 1.2624],\n",
      "        [1.6311, 1.8568, 1.0184, 3.3044],\n",
      "        [1.0243, 1.5240, 1.9544, 1.2167],\n",
      "        [1.9697, 1.4798, 1.2166, 1.2146]])\n"
     ]
    }
   ],
   "source": [
    "#矩阵的平方根\n",
    "import torch\n",
    "a = torch.rand(4,4)\n",
    "print(a.sqrt())\n",
    "print(a.rsqrt())#平方根的倒数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b0a70bd-99c9-498e-87ee-8fac9b1304e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4619, 0.7144, 0.0625, 0.5620],\n",
      "        [0.7420, 0.5616, 0.1651, 0.6337],\n",
      "        [0.5744, 0.2662, 0.0321, 0.5167],\n",
      "        [0.9296, 0.7954, 0.2457, 0.5150]])\n",
      "tensor([[-1.1144, -0.4852, -4.0008, -0.8314],\n",
      "        [-0.4304, -0.8325, -2.5989, -0.6580],\n",
      "        [-0.7998, -1.9096, -4.9635, -0.9526],\n",
      "        [-0.1053, -0.3303, -2.0251, -0.9575]])\n",
      "tensor([[-0.3355, -0.1460, -1.2043, -0.2503],\n",
      "        [-0.1296, -0.2506, -0.7823, -0.1981],\n",
      "        [-0.2408, -0.5748, -1.4942, -0.2868],\n",
      "        [-0.0317, -0.0994, -0.6096, -0.2882]])\n"
     ]
    }
   ],
   "source": [
    "#矩阵的对数\n",
    "import torch\n",
    "a = torch.rand(4,4)\n",
    "print(a)\n",
    "print(torch.log2(a))\n",
    "print(torch.log10(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50b5272f-f80a-4b84-bbc8-5acead4e9aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1416)\n",
      "tensor(3.)\n",
      "tensor(4.)\n",
      "tensor(3.)\n",
      "tensor(3.)\n",
      "tensor(0.1416)\n"
     ]
    }
   ],
   "source": [
    "#其他函数\n",
    "a = torch.tensor(3.1415926)\n",
    "print(a)\n",
    "print(a.floor())#向上取整\n",
    "print(a.ceil())#向下取整\n",
    "print(a.round())#四舍五入\n",
    "print(a.trunc())#取整数部分\n",
    "print(a.frac())#取小数部分 默认四位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71d8c4f-551f-44e8-9b22-0c8c7a192378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLR",
   "language": "python",
   "name": "dlr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
